# 哈希算法

不管是 「散列」还是 「哈希」，这都是中文翻译的差别，英文其实就是 **Hash**。

哈希算法的定义和原理非常简单：==将任意长度的二进制值串映射为固定长度的二进制值串==，这个<u>映射的规则</u>就是**哈希算法**；而通过原始数据映射之后得到的二进制值串就是**哈希值**。

哈希算法的要求：

- 从哈希值不能反向推导出原始数据，所以哈希算法也叫单向哈希算法；
- 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
- 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
- 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

举例： MD5 哈希算法

MD5 的哈希值是 **128 位 **的 Bit 长度，分别对 “今天我来讲哈希算法” 和 “jiajia” 这两个文本，计算 MD5 哈希值，得到两串看起来毫无规律的字符串。

```
MD5(" 今天我来讲哈希算法 ") = bb4767201ad42c74e650c1b6c03d78fa
MD5("jiajia") = cd611a31ea969b908932d44d126d195b
```

如果用 MD5 哈希算法分别计算只有一个感叹号差别的两个文本的的哈希值，尽管只有一字之差，得到的哈希值也是完全不同的。

```
MD5(" 我今天讲哈希算法！") = 425f0d5a917188d2c3c3dc85b5e4f2cb
MD5(" 我今天讲哈希算法 ") = a1fb91ac128e6aa37fe42c663971ac3d
```



哈希算法的应用非常非常多，最常见的七个，分别是安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。

## 安全加密

最常用于加密的哈希算法是 **MD5**（MD5 Message-Digest Algorithm，MD5 消息摘要算法）和**SHA**（Secure Hash Algorithm，安全散列算法）。

除了这两个之外，当然还有很多其他加密算法，比如**DES**（Data Encryption Standard，数据加密标准）、**AES**（Advanced Encryption Standard，高级加密标准）。

用于加密的哈希算法来说，有两点格外重要。

1. 第一点是很难根据哈希值反向推导出原始数据
2. 第二点是散列冲突的概率要很小。

第一点很好理解，加密的目的就是防止原始数据泄露，所以很难通过哈希值反向推导原始数据，这是一个最基本的要求。

第二点，实际上，不管是什么哈希算法，只能尽量减少碰撞冲突的概率，理论上是没办法做到完全不冲突的。

### 鸽巢原理

基于组合数学中一个非常基础的理论，鸽巢原理，也叫抽屉原理；鸽巢原理可以解释为什么哈希算法没办法做到完全不冲突的。

它是说，如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个，换句话说就是，肯定有 2 只鸽子在 1 个鸽巢内。

哈希算法产生的哈希值的长度是固定且有限的。比如 MD5 哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 $2^{128}$ 个数据，而要哈希的数据是无穷的。

- 基于鸽巢原理，如果对 $2^{128}+1$ 个数据求哈希值，就必然会存在哈希值相同的情况。一般情况下，哈希值越长的哈希算法，散列冲突的概率越低。

```
2^128=340282366920938463463374607431768211456
```

 MD5，有 2^128 个不同的哈希值，这个数据已经是一个天文数字了，所以散列冲突的概率要小于 $1/2^{128}$

越复杂、越难破解的加密算法，需要的计算时间也越长。比如 SHA-256 比 SHA-1 要更复杂、更安全，相应的计算时间就会比较长。

### 思考密码存储

> 思考：存储用户密码？

通过哈希算法，对用户密码进行加密之后再存储，最好选择相对安全的加密算法，比如 SHA 等（因为 MD5 已经号称被破解了），不过这样依然不够。

#### 字典攻击



字典攻击是指将**常用密码**的字典表中的每个密码用哈希算法计算哈希值，然后拿哈希值跟脱库后的密文比对。基本上就可以认为，这个加密之后的密码对应的明文就是字典中的这个密码。

针对字典攻击，可以引入一个==盐（salt）==，跟用户的密码组合在一起，增加密码的复杂度。拿组合之后的字符串来做哈希算法加密，将它存储到数据库中，进一步增加破解的难度。

## 唯一标识

==哈希算法可以对大数据做信息摘要，通过一个较短的二进制编码来表示很大的数据==。

如果要在海量的图库中，搜索一张图是否存在，不能单纯地用图片的元信息（比如图片名称）来比对，可以给每一个图片取一个唯一标识，或者说==信息摘要==。

- 比如，可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块
- 通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。
- 通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量。

## 数据校验

哈希算法用于 ==校验数据的完整性和正确性==。

BT 下载的原理是基于 P2P 协议的，下载的文件可能会被分割成很多文件块，可以通过哈希算法，对 全部 文件块分别取哈希值，并且保存在种子文件中

- 通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。
- 如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。

## 散列函数

散列函数更加看重的是==散列的平均性和哈希算法的执行效率==。

散列函数也是哈希算法的一种应用，相对哈希算法的其他应用，散列函数对于**散列算法冲突的要求要低很多**。即便出现个别散列冲突，只要不是过于严重，都可以通过开放寻址法或者链表法解决。

散列函数对于散列算法计算得到的值，是否能**反向解密也并不关心**。散列函数中用到的散列算法，更加关注散列后的值**是否能平均分布**地散列在各个槽中。

除此之外，散列函数执行的快慢，也会影响散列表的性能，所以散列函数用的散列算法一般都比较简单，比较**追求效率**。

## 负载均衡

在负载均衡中的应用就是利用哈希算法替代映射表，可以实现一个==会话粘滞的负载均衡策略==。

负载均衡算法有很多，比如轮询、随机、加权轮询等。会话粘滞（session sticky）的负载均衡算法就是需要在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。

最直接的方法就是，维护一张映射关系表，这张表的内容是客户端 IP 地址或者会话 ID 与服务器编号的映射关系。客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器。也有几个弊端：

- 如果客户端很多，映射表可能会很大，比较浪费内存空间；
- 客户端下线、上线，服务器扩容、缩容都会导致映射失效，这样维护映射表的成本就会很大；

可以通过==哈希算法==，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 这样，就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。

## 数据分片

在数据分片应用中，通过==哈希算法对处理的海量数据进行分片==，多机分布式处理，可以突破单机资源的限制。

> 举例1：1T 的日志文件记录用户的搜索关键词，需要快速统计出每个关键词被搜索的次数该怎么做呢？

难点：

1. 搜索日志很大，没办法放到一台机器的内存中
2. 只用一台机器来处理这么巨大的数据，处理时间会很长

针对两个难点，**可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度**：

- 用 n 台机器并行处理，从搜索记录的日志文件中，依次读出每个搜索关键词
- 通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号
- 哈希值相同的搜索关键词就被分配到了同一个机器上，即同一个搜索关键词会被分配到同一个机器上
- 每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。

处理过程也是 ==MapReduce== 的基本设计思想。



> 举例2：假设图库中有 1 亿张图片，如何快速判断图片是否在图库中？

难点：

1. 给每个图片取唯一标识（或者信息摘要），然后给1 亿张图片 构建散列表，是行不通的：单台机器的内存有限，而 1 亿张图片构建散列表显然远远超过了单台机器的内存上限



可以对数据进行分片，然后采用多机处理，准备 n 台机器，让每台机器只维护某一部分图片对应的散列表：

- 每次从图库中读取一个图片，计算**唯一标识**，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号
- 将这个图片的 唯一标识 和 图片路径 发往对应的机器构建散列表

当要判断一个图片是否在图库中的时候：

- 通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模
- 假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。

估算一下，给这 1 亿张图片构建散列表大约需要多少台机器，散列表中每个数据单元包含两个信息，哈希值和图片文件的路径

- 假设通过 MD5 来计算哈希值，那长度就是 128 比特，也就是 16 字节
- 文件路径长度的上限是 256 字节，可以假设平均长度是 128 字节
- 如果用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节。所以，散列表中每个数据单元就占用 152 字节
- 假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表
- 如果要对 1 亿张图片构建索引，需要大约十几台机器。

针对这种海量数据的处理问题，都可以采用多机分布式处理。借助这种==分片==的思路，可以突破单机内存、CPU 等资源的限制。

## 分布式存储

在分布式存储应用中，利用一致性哈希算法，可以==解决缓存等分布式系统的扩容、缩容==导致数据大量搬移的难题。

为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如**分布式缓存**。可以借用数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。

如果数据增多，就需要扩容，但并不是简单地加个机器就可以。

- 比如：原来的数据是通过与 10 来取模的，13 存储在编号为 3 这台机器上，新增一台机器中，对数据按照 11 取模，原来 13 这个数据就被分配到 2 号这台机器上。
- 所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上
- 相当于，缓存中的数据一下子就都失效了。所有的数据请求都会==穿透缓存==，直接去请求数据库。这样就可能发生[雪崩效应](https://zh.wikipedia.org/wiki/雪崩效应)，压垮数据库。

![image-20210202095737019](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210202095737.png)

### 一致性哈希算法

需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移。这时候，==一致性哈希算法==就要登场了。

假设有 k 个机器，数据的哈希值的范围是 [0, MAX]。将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间

- 当有新机器加入的时候，就将某几个小区间的数据，从原来的机器中搬移到新的机器中
- 这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。
- 除此之外，它还会借助一个虚拟的环和虚拟结点，更加优美地实现出来。

一致性哈希算法的应用非常广泛，在很多分布式存储系统中，都可以见到一致性哈希算法的影子。