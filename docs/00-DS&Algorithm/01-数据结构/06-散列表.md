# 散列表

**散列表**（Hash Table），也叫它哈希表或者Hash 表；散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。

散列表两个核心问题是**散列函数设计**和**散列冲突解决**。散列冲突有两种常用的解决方法，开放寻址法 和 链表法。

举例：通过6 位数字编号 来表示选手。

- 选手的编号叫作**键**（key）或者**关键字**；
- 参赛编号转化为数组下标的映射方法就叫作**散列函数**（或“Hash 函数”“哈希函数”）
- 散列函数计算得到的值就叫作 **散列值**（或 Hash 值、哈希值）

![image-20210201162554258](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201162554.png)

散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性。通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。

- 当按照键值查询元素时，用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。



## 散列函数

散列函数，顾名思义，它是一个函数。可以把它定义成**hash(key)**，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的==散列值==。

散列函数设计的基本要求：

1. 散列函数计算得到的散列值是一个==非负整数==；
2. 如果 key1 = key2，那 hash(key1) == hash(key2)
3. 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)

第一点：因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。

第二点：相同的 key，经过散列函数得到的散列值也应该是相同的。

第三点：要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的，业界著名的[MD5](https://zh.wikipedia.org/wiki/MD5)、[SHA](https://zh.wikipedia.org/wiki/SHA家族)、[CRC](https://zh.wikipedia.org/wiki/循環冗餘校驗)等哈希算法，也无法完全避免这种**散列冲突**。

## 散列冲突

散列函数也无法避免散列冲突，常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。

### 开放寻址法

开放寻址法的核心思想是，==如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入==。

#### 线性探测

**线性探测**（Linear Probing）：当往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，则从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。

举例：这里面黄色的色块表示空闲位置，橙色的色块表示已经存储了数据。

- 散列表的大小为 10，在元素 x 插入散列表之前，已经 6 个元素插入到散列表中。
- x 经过 Hash 算法之后，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以就产生了冲突。
- 于是就顺序地往后一个一个找，看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，于是再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置。

![image-20210201163125463](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201163125.png)

在散列表中**查找元素**的过程有点儿类似插入过程：

- 通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素
  - 如果相等，则说明就是要找的元素；
  - 否则就顺序往后依次查找。
- 如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。

![image-20210201163528627](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201163528.png)

散列表跟数组一样，不仅支持插入、查找操作，还支持删除操作。

对于使用线性探测法解决冲突的散列表，删除操作稍微有些特别，==不能单纯地把要删除的元素设置为空==。

- 在查找的时候，一旦我们通过线性探测方法，找到一个空闲位置，就可以认定散列表中不存在这个数据。
- 如果这个空闲位置是后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。
- 可以将删除的元素，**特殊标记为 deleted**。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。

![image-20210201163728539](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201163728.png)

线性探测法其实存在很大问题：

- 当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。
- 极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度为 O(n)。
- 在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。

除了线性探测方法之外，还有另外两种比较经典的探测方法，**二次探测**（Quadratic probing）和**双重散列**（Double hashing）。

#### 二次探测

二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是 hash(key)+0，hash(key)+1，hash(key)+2……

==二次探测探测的步长就变成了原来的 二次方== ，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+$1^2$，hash(key)+$2^2$……

#### 双重散列

双重散列，意思就是不仅要使用一个散列函数，使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……

- 先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数
- 依次类推，直到找到空闲的存储位置。

#### 装载因子

不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高，为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位，用**装载因子**（load factor）来表示空位的多少

装载因子的计算公式是：

```
散列表的装载因子 = 填入表中的元素个数 / 散列表的长度
```

装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

### 链表法

链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。

在散列表中，每个**桶**（bucket）或者**槽**（slot）会对应一条链表，所有散列值相同的元素都放到相同槽位对应的链表中。

![image-20210201164240551](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201164240.png)

当插入的时候，只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的==时间复杂度是 O(1)==。

当查找、删除一个元素时，同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除，时间复杂度跟链表的长度 k 成正比，也就是 ==O(k)==。

- 对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中 槽 的个数。



> 思考：Word 文档中单词拼写检查功能是如何实现的？

常用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，就算放大 10 倍也就是 20MB。

- 对于现在的计算机来说，这个大小完全可以放在**内存**里面。所以可以用散列表来存储整个英文单词词典。

当用户输入某个英文单词时，拿用户输入的单词去散列表中查找。

- 如果查到，则说明拼写正确；
- 如果没有查到，则说明拼写可能有误，给予提示。

借助散列表这种数据结构，就可以轻松实现快速判断是否存在拼写错误。



## 设计散列函数

散列函数的设计方法还有很多，比如直接寻址法、平方取中法、折叠法、随机数法等。

**散列函数的设计不能太复杂**：过于复杂的散列函数，势必会消耗很多计算时间，也就间接的影响到散列表的性能。

**散列函数生成的值要尽可能随机并且均匀分布**：这样才能避免或者最小化散列冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况。

### 装载因子

散列表，当装载因子过大时，可以进行==动态扩容==，重新申请一个更大的散列表，将数据搬移到这个新散列表中。

- 插入一个数据，最好情况下，不需要扩容，最好时间复杂度是 O(1)。
- 最坏情况下，散列表装载因子过高，启动扩容，我们需要重新申请内存空间，重新计算哈希位置，并且搬移数据，所以时间复杂度是 O(n)。
- 摊还分析法，均摊情况下，时间复杂度接近最好情况，就是 O(1)

对于动态散列表，随着数据的删除，散列表中的数据会越来越少，空闲空间会越来越多。如果我们对空间消耗非常敏感，可以在装载因子小于某个值之后，启动==动态缩容==。

### 动态扩容

为了解决一次性扩容耗时过多的情况，可以==将扩容操作穿插在插入操作的过程中，分批完成==。当装载因子触达阈值之后，只申请新空间，但并不 将老的数据搬移到新散列表中。

- 当有新数据要插入时，将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。
- 每次插入一个数据到散列表，都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。
- 这样没有了集中的一次性数据搬移，插入操作就都变得很快了。

![image-20210201174224685](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201174224.png)

对于查询操作，为了兼容了新、老散列表中的数据，先从新散列表中查找，如果没有找到，再去老的散列表中查找。

通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。这种实现方式，==任何情况下，插入一个数据的时间复杂度都是 O(1)==。

### 散列冲突解决

两种主要的散列冲突的解决办法，开放寻址法和链表法。这两种冲突解决办法在实际的软件开发中都非常常用。

- 比如，Java 中 LinkedHashMap 就采用了==链表法==解决冲突
- ThreadLocalMap 是通过==线性探测==的开放寻址法来解决冲突。

#### 开放寻址法

==当数据量比较小、装载因子小的时候，适合采用开放寻址法==。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因

优点

开放寻址法不像 链表法需要拉很多链表 。

1. 散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存**加快查询速度**。
2. 这种方法实现的散列表，**序列化起来比较简单**。链表法包含指针，序列化起来就没那么容易。

缺点

1. 用开放寻址法解决冲突的散列表，**删除数据的时候比较麻烦**，需要特殊标记已经删除掉的数据。
2. 在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，**冲突的代价更高**。
3. 所以，使用开放寻址法解决冲突的散列表，**装载因子的上限不能太大**。这也导致这种方法比链表法更浪费内存空间。

#### 链表法

==基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表==，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用==红黑树代替链表==。

优点

链表法对**内存的利用率**比开放寻址法要高。因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好。

链表法比起开放寻址法，**对大装载因子的容忍度更高**。

- 开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。
- 但是对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。

缺点

1. 链表因为要存储指针，所以对于比较小的对象的存储，是**比较消耗内存**的，还有可能会让内存的消耗翻倍。如果存储的是大对象，也就是说要存储的对象的大小远远大于一个指针的大小（4 个字节或者 8 个字节），那链表中指针的内存消耗在大对象面前就可以忽略了。

2. 因为链表中的结点是零散分布在内存中的，不是连续的，所以对 **CPU 缓存是不友好**的，这方面对于执行效率也有一定的影响

实际上，对链表法稍加改造，可以实现一个更加高效的散列表。

- 将链表法中的链表改造为其他高效的动态数据结构，比如跳表、红黑树。
- 这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 **O(logn)**。
- 这样也就有效避免了前面讲到的散列碰撞攻击。

![image-20210201175004486](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201175004.png)

## 工业级散列表举例

何为一个工业级的散列表？工业级的散列表应该具有哪些特性？

- 支持快速的查询、插入、删除操作；
- 内存占用合理，不能浪费过多的内存空间；
- 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。

实现这样一个散列表：

- 设计一个合适的散列函数；
- 定义装载因子阈值，并且设计动态扩容策略；
- 选择合适的散列冲突解决方法。



以Java 中的 HashMap 这样一个工业级的散列表举例。

### 初始大小

HashMap 默认的**初始大小是 16**，当然这个默认值是可以设置的，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。

### 装载因子和动态扩容

最大装载因子默认是 **0.75**，当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的**两倍**大小。

### 散列冲突解决方法

HashMap 底层采用==链表法==来解决冲突。即使负载因子和散列函数设计得再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。

在 JDK1.8 版本中，为了对 HashMap 做进一步优化，引入了红黑树。

- 而当==链表长度太长（默认超过 8）时，链表就转换为红黑树==。可以利用红黑树快速增删改查的特点，提高 HashMap 的性能。
- 当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表。因为在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显

### 散列函数

散列函数的设计并不复杂，追求的是简单高效、分布均匀。

JAVA规范中 hashcode本身是个32位整型值，在系统中，这个值对于不同的对象必须保证唯一。这也是就是重写equals必须重写hashcode的重要原因。

1. 获取对象的hashcode以后，先进行移位运算（hashcode >>> 16）
2. 再和自己做异或运算hashcode ^ (hashcode >>> 16)：将高16位移到低16位，这样计算出来的整型值将 具有 高位和低位的性质
3. 最后，用hash表当前的容量减去一，再和刚刚计算出来的整型值做位与运算。进行位与运算，是为了计算出数组中的位置。

之所以容量要减去一：

- 因为 A % B = A & (B - 1)；
- 本质上是「除留余数法」： (h ^ (h >>> 16)) & (capitity -1) = (h ^ (h >>> 16)) % capitity

可以看出，hashcode的随机性，加上移位异或算法，得到一个非常随机的hash值，再通过「除留余数法」，得到index，整体的设计过程与 】散列函数 设计原则非常吻合

```java
int hash(Object key) {
    int h = key.hashCode();
    // capicity 表示散列表的大小
    // (h ^ (h >>> 16)) % capitity
    return (h ^ (h >>> 16)) & (capitity -1); 
}
```

hashCode() 返回的是 Java 对象的 hash code。比如 String 类型的对象的 hashCode() 就是下面这样：

```java
public int hashCode() {
  int var1 = this.hash;
  if(var1 == 0 && this.value.length > 0) {
    char[] var2 = this.value;
    for(int var3 = 0; var3 < this.value.length; ++var3) {
      var1 = 31 * var1 + var2[var3];
    }
    this.hash = var1;
  }
  return var1;
}
```



## 散列表和链表

散列表这种数据结构虽然支持非常高效的数据插入、删除、查找操作，但是散列表中的数据都是通过散列函数打乱之后无规律存储的。也就说，它无法支持按照某种顺序快速地遍历数据。如果希望按照顺序遍历散列表中的数据，那需要将散列表中的数据拷贝到数组中，然后排序，再遍历。

散列表是动态数据结构，不停地有数据的插入、删除，所以每当希望按顺序遍历散列表中的数据的时候，都需要先排序，那效率势必会很低。为了解决这个问题，需要将散列表和链表（或者跳表）结合在一起使用。

### LRU 缓存淘汰算法

链表实现的 LRU 缓存淘汰算法的时间复杂度是 O(n)，借助散列表可以把 LRU 缓存淘汰算法的时间复杂度降低为 O(1)。

链表实现 LRU 缓存淘汰算法：

1. 需要维护一个按照访问时间从大到小有序排列的链表结构。因为缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，就直接将**链表头部**的结点删除。
2. 当要缓存某个数据的时候，先在链表中查找这个数据。
   1. 如果没有找到，则直接将数据放到链表的尾部；
   2. 如果找到了，我们就把它移动到链表的尾部。

缓存（cache）系统主要包含下面这几个操作：

- 往缓存中添加一个数据；
- 从缓存中删除一个数据；
- 在缓存中查找一个数据。

这三个操作都要涉及 查找 操作，如果单纯地采用链表的话，时间复杂度只能是 O(n)。如果将散列表和链表两种数据结构组合使用，可以将这三个操作的时间复杂度都降低到 O(1)。

使用双向链表存储数据，链表中的每个结点处理存储数据（data）、前驱指针（prev）、后继指针（next）之外，还新增了一个特殊的字段 hnext。

![image-20210201195601833](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201195602.png)

散列表是通过链表法解决散列冲突的，所以每个结点会在两条链中：

1. 一个链是**双向链表**，前驱和后继指针是为了将结点串在双向链表中
2. 另一个链是散列表中的**拉链**，next 指针是为了将结点串在散列表的拉链中。

#### 查找一个数据

散列表中查找数据的时间复杂度接近 O(1)，所以通过散列表，可以很快地在缓存中找到一个数据。当找到数据之后，还需要将它移动到双向链表的尾部。

#### 删除一个数据

到数据所在的结点，然后将结点删除。借助散列表，可以在 O(1) 时间复杂度里找到要删除的结点。

- 链表是双向链表，双向链表可以通过前驱指针 O(1) 时间复杂度获取前驱结点，所以在双向链表中，删除结点只需要 O(1) 的时间复杂度。

#### 添加一个数据

添加数据到缓存需要先看这个数据是否已经在缓存中。

- 如果已经在其中，需要将其移动到双向链表的尾部；
- 如果不在其中，还要看缓存有没有满。
  - 如果满了，则将双向链表头部的结点删除，然后再将数据放到链表的尾部
  - 如果没有满，就直接将数据放到链表的尾部。

通过散列表和双向链表的组合使用，实现了一个高效的、支持 LRU 缓存淘汰算法的缓存系统原型

### Redis 有序集合

Redis 有序集合的操作，那就是下面这样：

- 添加一个成员对象；
- 按照**key**（键值） 来删除一个成员对象；
- 按照键值 来查找一个成员对象；
- 按照**score**（分值） 区间查找数据，比如查找积分在 [100, 356] 之间的成员对象；
- 按照分值 从小到大排序成员变量；

如果仅仅按照分值将成员对象组织成跳表的结构，那按照键值来删除、查询成员对象就会很慢，解决方法与 LRU 缓存淘汰算法的解决方法类似。

可以再按照键值构建一个散列表，这样按照 key 来删除、查找一个成员对象的时间复杂度就变成了 O(1)，同时，借助跳表结构，其他操作也非常高效。

### Java LinkedHashMap

LinkedHashMap 是通过==双向链表和散列表这两种数据结构组合==实现的，不仅支持按照插入顺序遍历数据，还支持==按照访问顺序来遍历数据==。

LinkedHashMap 中的 Linked 实际上是指的是**双向链表**，并非指用链表法解决散列冲突。

```java
// 10 是初始大小，0.75 是装载因子，true 是表示按照访问时间排序
HashMap<Integer, Integer> m = new LinkedHashMap<>(10, 0.75f, true);
m.put(3, 11);
m.put(1, 12);
m.put(5, 23);
m.put(2, 22);
 
m.put(3, 26);
m.get(5);
 
for (Map.Entry e : m.entrySet()) {
  // 这段代码打印的结果是 1，2，3，5
  System.out.println(e.getKey());
}
```

每次调用 put() 函数，往 LinkedHashMap 中添加数据的时候，都会将数据添加到链表的尾部，所以，在前四个操作完成之后，链表中的数据是下面这样：

![image-20210201200959043](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201201000.png)

在第 8 行代码中，再次将键值为 3 的数据放入到 LinkedHashMap 的时候，会先查找这个键值是否已经有了，然后，再将**已经存在的 (3,11) 删除**，并且将新的 (3,26) 放到链表的尾部。

![image-20210201201035675](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201201035.png)

当第 9 行代码访问到 key 为 5 的数据的时候，**将被访问到的数据移动到链表的尾部**。所以，第 9 行代码之后，链表中的数据是下面这样：

![image-20210201201119534](https://aliyun-typora-img.oss-cn-beijing.aliyuncs.com/imgs/20210201201119.png)

最后打印出来的数据是 1，2，3，5。从上面的分析，按照访问时间排序的 LinkedHashMap 本身就是一个支持 LRU 缓存淘汰策略的缓存系统。实际上，它们两个的实现原理也是一模一样的。